---
title: "CT-SLEB"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Overview
This vignette provides a tutorial on the CT-SLEB method. CT-SLEB is a multi-ancestry polygenic risk score (PRS) method using summary statistics from genomewide association studies (GWAS) of multiple populations. The method contains three major steps: 1. Two-dimensional clumping and thresholding to select SNPs; 2. Empirical-Bayes method to estimate the effect sizes for the SNPs; 3. Super-learning step to combine PRS under different tuning parameters (p-value thresholds, clumping window size, r2-cutoff). We use [PLINK 1.90](https://www.cog-genomics.org/plink/1.9/) for clumping (flag: \-\-clump), which currently is not supported in PLINK 2.0. We use [PLINK 2.0](https://www.cog-genomics.org/plink/2.0/) for calculating PRS (command: \-\-score) because it allows calculating PRS with multiple effect sizes columns simultaneously (\-\-score-col-nums). We use R package for implementing empirical-Bayes and super-learning steps. For simplicity of demonstration, we will use the system( ) command to call plink directly from R. The user can also directly use plink through the terminal.


## Data and Software Preparation
Before starting the analyses, the user needs to download the following [example dataset](https://drive.google.com/file/d/1wswLKQmgYgkkog_vaDaVlLEmgoQS_xLG/view?usp=sharing). This dataset contains example data for chromosome 22. 
The folder contains the information: 1. summary statistics for five populations (named as _sumdata); 2. outcome for tuning and validation dataset (named as y_tuning and y_validation); 3. genotype data with 20,000 subjects for tuning and validation (named as AFR_test_chr); 4. The reference data from 1000 Genomes Projects (1KG) for the clumping step (named as: AFR_ref_chr22 and EUR_ref_chr22). The directory to this example dataset is set to be "data_dir" in the code. We also need to download PLINK 1.9 and PLINK 2.0. To distinguish the two software, we name PLINK 1.9 as plink and PLINK2.0 as plink2 in the code. 
```{r, echo=T,cache=F,warning=FALSE}
#install the CTSLEB package
#install.packages("devtools")
library(devtools)
#install_github("andrewhaoyu/CTSLEB")
library(CTSLEB)
library(data.table)
library(dplyr)
#Specify the directory to the data folder
data_dir = "data/"
#Specify the directory for the summary statistics
EUR_sumstats_file <- paste0(data_dir,"EUR_sumdata.txt") #  reference population
AFR_sumstats_file <- paste0(data_dir,"AFR_sumdata.txt") #  target population
#Specify the directory to the reference data for clumping purpose
EUR_ref_plinkfile <- paste0(data_dir,"EUR_ref_chr22")
AFR_ref_plinkfile <- paste0(data_dir,"AFR_ref_chr22")
#Specify the tuning and validation data directory
AFR_test_plinkfile <- paste0(data_dir,"AFR_test_chr22")
#Specify the directory to PLINK1.9 and PLINK2.0
plink19_exec <- "apps/plink"
plink2_exec <- "apps/plink2"
#Specify the directory to the result directory
out_dir = "test/"
outprefix <- "chr22"
```


## Step 1: Two-dimensional Clumping and Thresholding (CT)
To demonstrate the method, we use the GWAS summary statistics from Chromosome 22 for European (EUR) and African (AFR) to construct the PRS for the AFR population. First, we load the GWAS summary statistics for two populations. The summary statistics contain these columns: 1. CHR; 2. SNP: the SNP ID used in 1000 Genomes Project Phase 3 Data (1KG); 3. BP: SNP position (GRCh37); 4. A1: effect allele; 5. BETA: effect size; 6. SE: standard error of the effect size 7. P: p-value for the association test; 8. rs_id: the rsid of the SNP. EUR population is usually the GWAS with the largest sample size. Although I am using the EUR population as an example here, the other population is not limited to the EUR population. You can use GWAS from other populations as long as you put a corresponding reference for the clumping step.

Step1 extends the single ancestry clumping and thresholding method (CT) to the multi-ancestry setting. Instead of only applying the CT method on either the EUR or the target population, CT uses two-different p-value cutoffs to select variants. 

CT starts with the clumping step. We split the SNPs into two groups: 1. SNPs with p-values in the EUR population smaller than the target population. 2. Target population-specific SNPs or SNPs with p-values in the target population smaller than the EUR population. SNPs are clumped using the linkage disequilibrium (LD) estimates from the EUR population for the first group. Next, SNPs are clumped using the LD estimates from the target population. After the clumping, SNPs from the two groups are combined for the thresholding step for the second group.

```{r, echo=T,cache=T}
library(data.table)
#load data from the EUR and the target population
sum_EUR <- fread(paste0(data_dir,"EUR_sumdata.txt"),header=T)
sum_AFR <- fread(paste0(data_dir,"AFR_sumdata.txt"),header=T)
head(sum_EUR)
head(sum_AFR)
#Prepare the parameters for PLINK clumping purpose

PRS_farm <- SetParamsFarm(plink19_exec = plink19_exec,
                          plink2_exec = plink2_exec)
prs_mat <- dimCT(results_dir = out_dir,
                 sum_target = sum_AFR,
                 sum_ref = sum_EUR,
                 ref_plink = EUR_ref_plinkfile,
                 target_plink = AFR_ref_plinkfile,
                 test_target_plink = AFR_test_plinkfile,
                 out_prefix = outprefix,
                 params_farm = PRS_farm)
```
In this example, we only use one chromosome 22. If you are using workflow (i.e. Snakemake) which dispatches jobs by chromosome or chunks, you will need to combine the snp_list for all the jobs together before the Ebayes step. The order of clumping parameters is the same for each job. prs_mat contains 20000 samples. We will next use 10000 of these samples and calculate a set of tuning parameters. Phenotypes for tuning the target PRS is 
located in  "data/y_tuning.txt". The first two columns of prs_tune are the family id and individual ids. The target PRSs starts from the third column
```{r, echo=T,cache=T,warning=FALSE}
prs_tune <- prs_mat[1:10000,]
n.total.prs <- length(pthres)^2*length(r2_vec)*length(wc_base_vec)
prs_r2_vec_test <- rep(0,n.total.prs)

y_tune <- fread("data/y_tuning.txt")


for(p_ind in 1:n.total.prs){

  model <- lm(y_tune$V1~prs_tune[,(2+p_ind)])
  prs_r2_vec_test[p_ind] <- summary(model)$r.square
}

max_ind <- which.max(prs_r2_vec_test)

print(colnames(prs_tune)[max_ind+2])


```
## Step 2: Empirical-Bayes (EB) Estimation of Effect Sizes
Now we move to the EB step for estimating the regression coefficients of PRSs by using the genetic correlations of effect sizes across populations. At the end of two-dimensional clumping and thresholding step, we get SNP set with corresponding tuning parameters for estimating the covariance matrix for the prior distribution. In this particular example using data from chromosome 22, it's using clumping r2-cutoff at 0.01, window size at 10000kb, SNPs with p_EUR < 5E-08 or p_target < 0.05. In real data analyses, PRSs need to be calculated based on all chromsome together to determine the SNP set. 
```{r, echo=T,cache=T,warning=FALSE}
#find the best snp set
best_snps <- colnames(prs_tune)[max_ind+2]
#calculate eb effect using EB coefficients
prs_mat_eb <- CalculateEBEffectSize(bfile = AFR_test_plinkfile ,
                                    snp_ind = best_snps,
                                    plink_list = plink_list,
                                    out_prefix = outprefix,
                                    results_dir = out_dir,
                                    params_farm = PRS_farm)
```

## Step 3: Super Learning
In Step 3, we input all the PRSs and tuning parameters to train the super-learning model and predict the outcome. The super-learning model is a linear combination of different predictors based on multiple supervised learning algorithms. The set of prediction algorithm can be self-designed or chosen from classical prediction algorithms. In this tutorial, we will use the Lasso, ridge regression and neural networks as our predictors. Other predictors can also be selected. The R package SuperLearner is used in this step. Detailed guidance of SuperLearner 
package can be found at: 
https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html. The prs_mat_eb data.frame created at the end of Step2 contains 20,000 samples. We will split these samples into a tuning and final validation sets.  The first 10,000 samples will be the tuning set and the second 10,000 samples the validation set. The PRSTrainValSplit() will perform this spit and also drop all the PRS 
columns with a pairwise correlation greater than 0.98.
```{r, echo=T,cache=T,warning=FALSE}
library(caret)
y_vad_file <- paste0(data_dir,"y_validation.txt")
y_vad <- fread(y_vad_file)

train_val_list <- PRSTrainValSplit(x = prs_mat_eb)
prs_tune_sl <- train_val_list[[1]]
prs_valid_sl <- train_val_list[[1]]
```
Next train the super-learning model
```{r, echo=T,cache=T,warning=FALSE}
library(SuperLearner)
library(ranger)
library(glmnet)

SL.libray <- c(
  "SL.glmnet",
  "SL.ridge",
  "SL.nnet"
  #"SL.bayesglm"
  #"SL.stepAIC"
  #"SL.xgboost"
  #"SL.randomForest"
  #"SL.ksvm",
  #"SL.bartMachine",
  #"SL.kernelKnn",
  #"SL.rpartPrune",
  #"SL.lm"
  #"SL.mean"
)

sl <- SuperLearner(Y = y_tune$V1, 
                   X = prs_tune_sl, 
                   family = gaussian(),
                   SL.library = SL.libray)
```
Predict the outcome using the independent validation dataset and evaluate the CT-SLEB PRS performance.
```{r, echo=T,cache=T,warning=FALSE}


y_pred <- predict(sl, prs_valid_sl, onlySL = TRUE)



model <- lm(y_vad$V1~y_pred[[1]])
r2_ctsleb <- summary(model)$r.square
print(r2_ctsleb)
```
