---
title: "CT-SLEB"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Overview
This vignette provides a tutorial on the CT-SLEB method. CT-SLEB is a multi-ancestry polygenic risk score (PRS) method using summary statistics from genomewide association studies (GWAS) of multiple populations. The method contains three major steps: 1. Two-dimensional clumping and thresholding to select SNPs; 2. Empirical-Bayes method to estimate the effect sizes for the SNPs; 3. Super learning step to combine PRS under different tuning parameters (p-value thresholds, clumping window size, r2-cutoff). We use [PLINK 1.90](https://www.cog-genomics.org/plink/1.9/) for clumping (flag: \-\-clump), which currently is not supported in PLINK 2.0. We use [PLINK 2.0](https://www.cog-genomics.org/plink/2.0/) for calculating PRS (command: \-\-score) because it allows calculating PRS with multiple effect sizes columns simultaneously (\-\-score-col-nums). We use R package for implementing empirical-Bayes and super-learning steps. For simplicity of demonstration, we will use the system( ) command to call plink directly from R. The user can also directly use plink through the terminal.


## Data and Software Preparation
Before the starting the analyses, the user need to download the following [example dataset](https://drive.google.com/file/d/1wswLKQmgYgkkog_vaDaVlLEmgoQS_xLG/view?usp=sharing). This dataset contains an example data for chromosome 22. The folder contains the information: 1. summary statistics for five populations (named as _sumdata); 2. outcome for tuning and validation dataset (named as y_tuning and y_validation); 3. genotype data with 20,000 subjects for tuning and validation (named as AFR_test_chr); 4. The reference data from 1000 Genomes Projects (1KG) for the clumping step (named as: AFR_ref_chr22 and EUR_ref_chr22). The directory to this example dataset is named as "data.dir" in the code. We also need to download PLINK 1.9 and PLINK 2.0. To distinguish the two software, we name PLINK 1.9 as plink and PLINK2.0 as plink 2 in the code. The directory to PLINK is named as "soft.dir". We also need to create a temporary folder for saving intermediate output from PLINK (e.g. clumping results, PRSs). We name this folder as "temp.dir". The user can specify three directory using their local information. 
```{r, echo=T,cache=T,warning=FALSE}
#we will create a temporary folder to save the clumping results and prs
#reference data from 1KG is saved in data.dir
#download the example dataset using command:
#wget https://drive.google.com/file/d/1wswLKQmgYgkkog_vaDaVlLEmgoQS_xLG/view?usp=sharing
#uncompress the data.zip by command: unzip data.zip
#the user can specific their own temp.dir, soft.dir and data.dir
system("mkdir ../test/temp.dir")
temp.dir = "../test/temp.dir/"
soft.dir = "../test/"
data.dir = "../data/"

#install the CTSLEB package
#install.packages("devtools")
library(devtools)
#install_github("andrewhaoyu/CTSLEB")
library(CTSLEB)
```

## Alignment SNPs Across Populations
To demonstrate the mehtod, we use the GWAS summary statistics from Chromosome 22 for European (EUR) and African (AFR) to construct the PRS for AFR population. First, we load the GWAS summary statistics for two populations. The summary statistics contain these columns: 1. CHR; 2. SNP: the SNP ID used in 1000 Genomes Project Phase 3 Data (1KG); 3. BP: SNP position (GRCh37); 4. A1: effect allele; 5. BETA: effect size; 6. SE: standard error of the effect size 7. P: p-value for the association test; 8. rs_id: the rsid of the SNP. 
```{r, echo=T,cache=T}
library(data.table)
#load data from EUR and target population
sum_EUR = fread(paste0(data.dir,"EUR_sumdata.txt"),header=T)
sum_AFR = fread(paste0(data.dir,"AFR_sumdata.txt"),header=T)
head(sum_EUR)
head(sum_AFR)
```
Since the SNPs and effect allele in the EUR and AFR are not the same, we align SNPs and the alleles to be the same with reference to AFR (the target population).
```{r, echo=T,cache=T,warning=FALSE}
library(dplyr)

#align GWAS summary stat to the target population
sum_com <- AlignSum(sum_tar = sum_AFR,
                    sum_other = sum_EUR)
head(sum_com)
```
EUR population is usually the GWAS with largest sample size. Altough I am using the EUR population as an example here, the other population is not limited to the EUR population. You can use GWAS from other populations as long as you put corresponding reference for the clumping step.


## Step 1: Two-dimensional Clumping and Thresholding (CT)
Step1 extends the single ancestry clumping and thresholding method (CT) to multi-ancestry setting. Instead of only applying the CT method on either the EUR or the target population, CT uses two-different p-value cutoffs to select variants. 

CT starts with the clumping step, we split the SNPs into two groups: 1. SNPs with p-value in the EUR population smaller than the target population. 2. Target population-specific SNPs or SNPs with p-value in the target population smaller than the EUR population. For the first group, SNPs are clumped using the linkage disequilibrium (LD) estimates from the EUR population. For the second group, SNPs are clumped using the LD estimates from the target population. After the clumping, SNPs from the two groups are combined together for the thresholding step. 

```{r, echo=T,cache=T,warning=FALSE}
#split the SNPs into two groups
sum_com_split <- SplitSum(sum_com)
#sum_com_split is a list with two data frame
#the first data frame contains SNPs with p_eur < p_target, the P value column is from p_eur
sum_other_ref = sum_com_split[[1]]
#the second data frame contains target population-specific SNPs or p_eur < p_target. The p-value column is from p_target. 
sum_tar_ref = sum_com_split[[2]]

# we use plink1.9 for the clumping purpose
# specify vector for clumping r squre and base window size
#the clumping_window_ize = base_window_size/clumping_r_square so that lower clumping r2 can have larger clumping window size
r2_vec = c(0.01,0.05,0.1,0.2,0.5,0.8)
wc_base_vec = c(50,100)


write.table(sum_other_ref,paste0(temp.dir,"sum_other_ref"),col.names = T,row.names = F,quote=F)
write.table(sum_tar_ref,paste0(temp.dir,"sum_tar_ref"),col.names = T,row.names = F,quote=F)
# --clump-p1 determines the upper bound of p-value to be kept in the clumping. We set it as 1.
# --clump-r2 is the clumping r square
# --clump-kb is the clumping window size
snp_list = list()
temp = 1
for(r_ind in 1:length(r2_vec)){
  #create the window size given the clumping r2
  wc_vec = wc_base_vec/r2_vec[r_ind]
  for(w_ind in 1:length(wc_vec)){
    pthr = 1
    r2thr = r2_vec[r_ind]
    kbpthr = wc_vec[w_ind]
    #for the first group, we perform clumping using EUR as reference   
    system(paste0(soft.dir,"plink ",
    "--bfile ",data.dir,"EUR_ref_chr22 ",
    "--clump ",temp.dir,"sum_other_ref ",
    "--clump-p1 ",pthr," ",
    "--clump-r2 ",r2thr," ",
    "--clump-kb ",kbpthr," ",
    "--out ", temp.dir,"EUR_ref_CT_rind_",r_ind,"_wcind_",w_ind))
    #for the second group, we perform clumping using AFR as reference
    system(paste0(soft.dir,"plink ",
    "--bfile ",data.dir,"AFR_ref_chr22 ",
    "--clump ",temp.dir,"sum_tar_ref ",
    "--clump-p1 ",pthr," ",
    "--clump-r2 ",r2thr," ",
    "--clump-kb ",kbpthr," ",
    "--out ", temp.dir,"AFR_ref_CT_rind_",r_ind,"_wcind_",w_ind))
    
    #combine the SNPs from the two clumping groups
   LD_EUR= fread(paste0(temp.dir,"EUR_ref_CT_rind_",r_ind,"_wcind_",w_ind,".clumped"))[,3,drop=F]
   LD_tar = fread(paste0(temp.dir,"AFR_ref_CT_rind_",r_ind,"_wcind_",w_ind,".clumped"))[,3,drop=F]
    LD  = rbind(LD_EUR,LD_tar)
    snp_list[[temp]] = LD
    names(snp_list[[temp]]) = paste0("clump_r2_",r2thr,"_ws_",kbpthr)
    temp = temp + 1
  }
}

#snp_list contains SNPs ID with different clumping parameters
```

After the clumping step, we are moving to the thresholding step by varying p-value thresholds on both the European and the target populations. We use the regression coefficients from the target population to construct the PRS with the"\-\-score-col-nums" command in plink2. To implement this step, we need to create a file with coefficients for PRSs under different clumping parameters. 
```{r, echo=T,cache=T,warning=FALSE}
#create a coefficient matrix 
#rows are the total number of SNPs
#number of columns as 12 (6 clumping r2-cutoff * 2 base_window_size)
#each column contains the regression coefficients of the target population for SNPs after LD-clumping under a combination of r2-cutoff and base_window_size

#plink2 need three files to compute PRS under different thresholds
#The first file is a score_file, which contains the coefficients for SNPs
#The second file is a p_value_file, which contains the p_value for SNPs
#The third file is a q_range file, which contains the p_value thresholds
#We use PreparePlinkFile() to create score_file and p_value_file
#We use CreateQRange() to create q_range_file
#PreparePlinkFile() need to parameters
#snp_list is the result from the two-dimensional clumping step
#sum_com is the result from AlignSum() function
plink_file = PreparePlinkFile(snp_list,sum_com)

#score_file description
#the first column contains the unique SNPs after clumping results under all combinations of r2-cutoff and window_size
#the second column is the effect allele
#the third to the last columns contains the regression coefficients of the target population for SNPs after LD-clumping under a specific combination of r2-cutoff and base_window_size
#the coefficients is put as 0 if a SNP doesn't exist in the clumping results under a specific combination of r2-cutoff and base_window_size
score_file = plink_file[[1]]
write.table(score_file,file = paste0(temp.dir,"score_file"),row.names = F,col.names = F,quote=F)
#p_value_file description
#the first column is the same as score_file
#the second column is the p-values of SNPs from the GWAS of the target population
p_value_file = plink_file[[2]]
# unique_infor description
#unique_infor contains the information for all SNPs after the clumping step
#unique_infor has SNP, CHR, BP, A1 (effect_allele), 
#(BETA, SE, P) for the target population, 
#(BETA_other, SE_other,P_other) for the EUR  population
unique_infor = plink_file[[3]]
#specific p-value threshold
pthres <- c(5E-08,5E-07,5E-06,5E-05,5E-04,5E-03,5E-02,5E-01,1.0)
#create q-range file
q_range = CreateQRange(pthres)
head(q_range)
#plink2 will select SNPs fall into the range between small_P and max_P to calculate PRS for each row in q_range
#more details of this command can be found https://www.cog-genomics.org/plink/2.0/score
write.table(q_range,file = paste0(temp.dir,"q_range_file"),row.names = F,col.names = F,quote=F)


#vary the p-values under two dimensions
#select SNPs with p_target < cutoff1 | p_other < cutoff2
#the current p-value file contains the P-value from the target population
#--q-score-range command select SNPs under specific p-value threshold given p_value_file
#To select the SNPs with p-value in European less than cutoff2,
#we put the p-value of these SNPs as 0 in the p-value file, so that they are guarated to be selected.

#create a temporary p_value_file
p_value_file_temp = p_value_file
    for(k1 in 1:length(pthres)){
      #keep al the SNPs with P_EUR less than pthres[k1] in the analyses
      idx <- which(unique_infor$P_other<=pthres[k1])
      p_value_file_temp$P[idx] = 0
      write.table(p_value_file_temp,file = paste0(temp.dir,"p_value_file"),col.names = F,row.names = F,quote=F)
      n_col = ncol(score_file)

 res = system(paste0(soft.dir,"plink2 ",
                            "--q-score-range ",temp.dir,"q_range_file ",temp.dir,"p_value_file ",
                            "--score-col-nums 3-",n_col," ",
                            "--score ",temp.dir,"score_file  ",
                            "--bfile ",data.dir,"AFR_test_chr22 ",
                            "--out ",temp.dir,"prs_p_other_",k1))
 #the output of plink2 create 9 different files named as prs_p_other_k1.p_tar_k2.sscore
 #this output file contains 16 columns
 #the column 1-4 are: family ID, individual ID, 2*total number of SNPs in the PRS, the sum of allele count
 #column 5-16 are the PRS scores with SNP of p_target<p_thres[k2]|p_eur<p_thres[k1] for different combinations of r2-cutoff and base_window_size
    }
```


```{r, echo=T,cache=T,warning=FALSE}
#combine all the prs
prs_list = list()
temp = 1
#take the column name of different clumping parameters
names = colnames(score_file)[3:ncol(score_file)]
for(k1 in 1:length(pthres)){
  for(k2 in 1:length(pthres)){
  #the --score command in plink2 computes PRS as G*beta/(2*number of SNPs)
 #This doesn't affect prediction R2 of the PRS if you compute PRS for all chromosomes together
 #But if you compute PRS by chromosome, you need to times (2*number of SNPs) before sum the score together
#here I am scaling the score by (2*number of SNPs) to aviod this potential
    
    #load PRS for SNPs with p_target<p_thres[k2]|p_eur<p_thres[k1] 
    prs_temp = fread(paste0(temp.dir,"prs_p_other_",k1,".p_tar_",k2,".sscore"))
    # times (2*number of SNPs)
    prs_list[[temp]] = prs_temp[,5:ncol(prs_temp)]*2*nrow(score_file)
   
    colnames(prs_list[[temp]]) = paste0(names,"_","p_other_",pthres[k1],"_p_tar_",pthres[k2])
    temp = temp + 1
  }
}
prs_mat = as.data.frame(cbind(prs_temp[,1:2],bind_cols(prs_list)))
prs_tun = prs_mat[1:10000,]

#find the best R-square among the all the PRSs to find candidate set
#we use this candidate for estimating covariance matrix for the prior distribution
#create prediction r2 vector to store r2 for different prs
n.total.prs = length(pthres)^2*length(r2_vec)*length(wc_base_vec)
prs_r2_vec_test = rep(0,n.total.prs)
#load the phenotype data for the tuning set
y_tun = fread("../data/y_tuning.txt")
for(p_ind in 1:n.total.prs){
  #the first two columns of prs_tun are family id and individual id
  #prs starts from the third column
  model = lm(y_tun$V1~prs_tun[,(2+p_ind)])
  prs_r2_vec_test[p_ind] = summary(model)$r.square
}
max_ind = which.max(prs_r2_vec_test)
#+2 is due to the first two columns are family id and individual id
print(colnames(prs_tun)[max_ind+2])
```
## Step 2: Empirical-Bayes (EB) Estimation of Effect Sizes
Now we move to the EB step for estimating the regression coefficients of PRSs by using the genetic correlations of effect sizes across populations. At the end of two-dimensional clumping and thresholding step, we get SNP set with corresponding tuning parameters for estimating the covariance matrix for the prior distribution. In this particular example using data from chromosome 22, it's using clumping r2-cutoff at 0.5, window size at 100kb, SNPs with p_EUR < 5E-08 or p_target < 5E-08. In real data analyses, PRSs need to be calculated based on all chromsome together to determine the SNP set. 
```{r, echo=T,cache=T,warning=FALSE}
#Get the SNP set with the best performance in the CT step
snp_set_ind = colnames(prs_tun)[max_ind+2]
SNP_set = GetSNPSet(snp_set_ind,
                    score_file,
                    unique_infor)
#SNP_set is used for estimating the covariance matrix for the prior distribution
#Estimate the EB posterior mean for all SNPs in unqiue_infor
unique_infor_post = EBpost(unique_infor,SNP_set)
#get the posterior coefficient matrix
post_beta_mat = cbind(unique_infor_post$BETA_EB_target,unique_infor_post$BETA_EB_other)
colnames(post_beta_mat) = c("EB_target","EB_eur")

#PreparePlinkFileEB is similar as PreparePlinkFile function
#we use this to prepare the files needed for PLINK2 --score command
#PreparePlinkFileEB create the coefficients matrix for PRS for all ancestries in post_beta_mat
#Instead of only using the EB coefficient for the target population
#we also calculate the PRS using the EB coefficients using EUR population
#we will put all the PRSs in this as input for super learning model
plink_file_eb = PreparePlinkFileEB(snp_list,
                            unique_infor_post,
                            post_beta_mat)
#score_file description
#the first column contains the unique SNPs after clumping results under all combinations of r2-cutoff and window_size
#the second column is the effect allele
#the third to the last columns contains the regression coefficients of the EUR and target population for SNPs after LD-clumping under a specific combination of r2-cutoff and base_window_size
#the coefficients is put as 0 if a SNP doesn't exist in the clumping results under a specific combination of r2-cutoff and base_window_size
score_file = plink_file_eb[[1]]
write.table(score_file,file = paste0(temp.dir,"score_file_eb"),row.names = F,col.names = F,quote=F)
#p_value_file description
#the first column is the same as score_file
#the second column is the p-values of SNPs from the GWAS of the target population
p_value_file = plink_file_eb[[2]]
```

```{r, echo=T,cache=T,warning=FALSE}
#vary the p-values under two dimensions
#select SNPs with p_target < cutoff1 | p_other < cutoff2
#the current p-value file contains the P-value from the target population
#--q-score-range command select SNPs under specific p-value threshold given p_value_file
#To select the SNPs with p-value in European less than cutoff2,
#we put the p-value of these SNPs as 0 in the p-value file, so that they are guarated to be selected.



#create a temporary p_value_file
p_value_file_temp = p_value_file
    for(k1 in 1:length(pthres)){
      #keep al the SNPs with P_EUR less than pthres[k1] in the analyses
      idx <- which(unique_infor$P_other<=pthres[k1])
      p_value_file_temp$P[idx] = 0
      write.table(p_value_file_temp,file = paste0(temp.dir,"p_value_file"),col.names = F,row.names = F,quote=F)
      n_col = ncol(score_file)

 res = system(paste0(soft.dir,"plink2 ",
                            "--q-score-range ",temp.dir,"q_range_file ",temp.dir,"p_value_file ",
                            "--score-col-nums 3-",n_col," ",
                            "--score ",temp.dir,"score_file_eb  ",
                            "--bfile ",data.dir,"AFR_test_chr22 ",
                            "--out ",temp.dir,"eb_prs_p_other_",k1))
 #the output of plink2 create 9 different files named as prs_p_other_k1.p_tar_k2.sscore
 #this output file contains 16 columns
 #the column 1-4 are: family ID, individual ID, 2*total number of SNPs in the PRS, the sum of allele count
 #column 5-16 are the PRS scores with SNP of p_target<p_thres[k2]|p_eur<p_thres[k1] for different combinations of r2-cutoff and base_window_size
    }

#combine all the prs
prs_list = list()
temp = 1
#take the column name of different clumping parameters
names = colnames(score_file)[3:ncol(score_file)]
for(k1 in 1:length(pthres)){
  for(k2 in 1:length(pthres)){
  #the --score command in plink2 computes PRS as G*beta/(2*number of SNPs)
 #This doesn't affect prediction R2 of the PRS if you compute PRS for all chromosomes together
 #But if you compute PRS by chromosome, you need to times (2*number of SNPs) before sum the score together
#here I am scaling the score by (2*number of SNPs) to aviod this potential
    
    #load PRS for SNPs with p_target<p_thres[k2]|p_eur<p_thres[k1] 
    prs_temp = fread(paste0(temp.dir,"eb_prs_p_other_",k1,".p_tar_",k2,".sscore"))
    # times (2*number of SNPs)
    prs_list[[temp]] = prs_temp[,5:ncol(prs_temp)]*2*nrow(score_file)
   
    colnames(prs_list[[temp]]) = paste0(names,"_","p_other_",pthres[k1],"_p_tar_",pthres[k2])
    temp = temp + 1
  }
}
prs_mat = as.data.frame(cbind(prs_temp[,1:2],bind_cols(prs_list)))
 #we have got the PRSs calcualted based on EB coefficients of the EUR and the target population under all combinations of clumping r2-cutoff, window size, p-value thresholds
```

## Step 3: Super Learning
In step 3, we use all the PRSs under differnt tuning parameters as the input and train the super learning model on the tuning dataset to predict the outcome. The super-learning model is a linear combination of different predictors based on multiple supervised learning algorithms. The set of prediction algorithm can be self-designed or chosen from classicial prediction algorithms. In this tutorial, we chosse Lasso, ridge regression and neural networks as our predictors. The user can also choose other predictors. We use the R package SuperLearner to implement this step. Detailed guidance of SuperLearner package can be found at: https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html. 
```{r, echo=T,cache=T,warning=FALSE}
#load the phenotype data for the tuning set
y_tun = fread("../data/y_tuning.txt")
#load the phenotype data for the validation set
y_vad = fread("../data/y_validation.txt")
#prs_mat contains 20,000 subjects,
#the first 10,000 subject of prs.mat is used as tuning set
#the second 10,000 subject of prs.mat is used as final validation set
#drop the first two ID columns
n.test = 10000
prs_tun = as.data.frame(prs_mat[1:n.test,-c(1:2),drop=F])
prs_vad = as.data.frame(prs_mat[(n.test+1):nrow(prs_mat),-c(1:2),drop=F])
#we first dorp all the prs columns with pairwise correlation more than 0.98
mtx = cor(prs_tun)
library(caret)
drop = findCorrelation(mtx,cutoff=0.98)
drop = names(prs_tun)[drop]
prs_tun_clean = prs_tun %>% 
  select(-all_of(drop))
prs_vad_clean = prs_vad %>% 
  select(-all_of(drop))
library(SuperLearner)
library(ranger)
#choose the prediction algorithms
SL.libray <- c(
  "SL.glmnet",
  "SL.ridge",
   "SL.nnet"
  #"SL.bayesglm"
  #"SL.stepAIC"
  #"SL.xgboost"
  #"SL.randomForest"
  #"SL.ksvm",
  #"SL.bartMachine", 
  #"SL.kernelKnn",
  #"SL.rpartPrune", 
  #"SL.lm"
  #"SL.mean"
)

#train the super-learning model
sl = SuperLearner(Y = y_tun$V1, X = prs_tun_clean, family = gaussian(),
                  # For a real analysis we would use V = 10.
                  # V = 3,
                  SL.library = SL.libray)

#predict the outcome using the independent validation dataset
y_pred <- predict(sl, prs_vad_clean, onlySL = TRUE)
#evaluate the CT-SLEB prs performance on the validation
model <- lm(y_vad$V1~y_pred[[1]])
r2_ctsleb <- summary(model)$r.square
print(r2_ctsleb)
```


## GWAS Data Avaiable From More Than Two Ancestries
In step 3, we use all the PRSs under differnt tuning parameters as the input and train the super learning model on the tuning dataset to predict the outcome. The super-learning model is a linear combination of different predictors based on multiple supervised learning algorithms. The set of prediction algorithm can be self-designed or chosen from classicial prediction algorithms. In this tutorial, we chosse Lasso, ridge regression and neural networks as our predictors. The user can also choose other predictors. We use the R package SuperLearner to implement this step. Detailed guidance of SuperLearner package can be found at: https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html. 
